# -*- coding: utf-8 -*-
"""lin_alg_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17yNzPdtqbggOcJxUcs2Rt4aBLCsqBYrk
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# Page configuration
st.set_page_config(page_title="Affordable Housing Prediction in New York City", layout="wide")

# Preprocessing:
# Load the dataset with specified columns
df = pd.read_csv('Affordable_Housing_Production_by_Building_20241120.csv', usecols=[
    'Project ID', 'Building ID', 'Number', 'Street', 'Borough',
    'Postcode', 'BBL', 'BIN', 'Community Board', 'Council District', 'Census Tract',
    'NTA - Neighborhood Tabulation Area', 'Reporting Construction Type',
    'Extended Affordability Only', 'Prevailing Wage Status',
    'Extremely Low Income Units', 'Very Low Income Units',
    'Low Income Units', 'Moderate Income Units', 'Middle Income Units',
    'Other Income Units', 'All Counted Units', 'Total Units', 'Latitude', 'Longitude'
])

# Define different feature sets
feature_sets = {
  "All Features": ['Borough', 'Census Tract', 'NTA - Neighborhood Tabulation Area',
                     'Reporting Construction Type', 'Extended Affordability Only',
                     'Prevailing Wage Status', 'All Counted Units', 'Total Units'],
  "Excluding Construction Type": ['Borough', 'Census Tract', 'NTA - Neighborhood Tabulation Area',
                                   'Extended Affordability Only', 'Prevailing Wage Status',
                                   'All Counted Units', 'Total Units'],
  "Excluding Prevailing Wage Status": ['Borough', 'Census Tract', 'NTA - Neighborhood Tabulation Area',
                                       'Reporting Construction Type', 'Extended Affordability Only',
                                       'All Counted Units', 'Total Units'],
  "Excluding All Counted Units": ['Borough', 'Census Tract', 'NTA - Neighborhood Tabulation Area',
                                  'Reporting Construction Type', 'Extended Affordability Only',
                                  'Prevailing Wage Status', 'Total Units']
}

# Preprocess data for each feature set
model_results = {}
for feature_set_name, feature_cols in feature_sets.items():
  # Filter relevant data
  data_filtered = df[feature_cols + ['Extremely Low Income Units', 'Very Low Income Units', 'Low Income Units']].copy()

  # Combine target columns to create a binary target variable
  data_filtered['Low_Income'] = data_filtered[['Extremely Low Income Units', 'Very Low Income Units', 'Low Income Units']].sum(axis=1) > 0
  data_filtered['Low_Income'] = data_filtered['Low_Income'].astype(int)

  # Drop the original target columns
  data_filtered = data_filtered.drop(columns=['Extremely Low Income Units', 'Very Low Income Units', 'Low Income Units'])

  # Handle missing values
  data_filtered = data_filtered.dropna()

  # Separate features and target
  X = data_filtered[feature_cols]
  y = data_filtered['Low_Income']

  # One-hot encode categorical features
  categorical_cols = [col for col in feature_cols if col in ['Borough', 'NTA - Neighborhood Tabulation Area',
                                                               'Reporting Construction Type', 'Extended Affordability Only',
                                                               'Prevailing Wage Status']]
  encoder = OneHotEncoder(drop='first', sparse_output=False)
  X_encoded = encoder.fit_transform(X[categorical_cols]) if categorical_cols else np.empty((X.shape[0], 0))

  # Standardize numerical features
  numerical_cols = [col for col in feature_cols if col in ['Census Tract', 'All Counted Units', 'Total Units']]
  scaler = StandardScaler()
  X_scaled = scaler.fit_transform(X[numerical_cols]) if numerical_cols else np.empty((X.shape[0], 0))

  # Combine processed features
  X_preprocessed = np.hstack([X_encoded, X_scaled])

  # Split data into training and testing sets
  X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)

  # Train logistic regression model
  model = LogisticRegression(random_state=42, max_iter=500)
  model.fit(X_train, y_train)

  # Predict on test data
  y_pred = model.predict(X_test)
  y_pred_proba = model.predict_proba(X_test)[:, 1]

  # Calculate performance metrics
  accuracy = accuracy_score(y_test, y_pred)
  auc = roc_auc_score(y_test, y_pred_proba)

  # Store results
  model_results[feature_set_name] = {
        "Model": model,
        "Accuracy": accuracy,
        "AUC": auc,
        "y_test": y_test,
        "y_pred": y_pred,
        "y_pred_proba": y_pred_proba,
  }

# Header
st.title("Affordable Housing Prediction in New York City")
st.markdown("""
This app uses logistic regression to predict and visualize the likelihood of housing units being affordable for extremely-low, low, and moderately-low income individuals
based on the Affordable Housing Production by Building dataset from NYC OpenData. We will do this with the intention of determining which features are
most strongly associated with low-income housing availability, and to model the lack of quality housing for low-income New Yorkers.
We aim to make understanding housing inequality in New York City more accessible by providing an interactive way for New Yorkers to learn more about
low-income housing and the variables that affect it. Further, we hope that this aids public awareness and advocacy for equitable housing policies.

""")

# Making tabs for data and takeaways
tab1, tab2, tab3, tab4, tab5 = st.tabs(["Data", "Feature Importance", "Alt. Model 1 - No Construction Type", "Alt. Model 2 - No All Unit Counts", "Alt. Model 3 - No Prevailing Wage Status"])

# Overall model tab
with tab1:

  # Displaying a map of our dataset
  st.write("### Map of Housing Units")
  st.map(df[['Latitude', 'Longitude']].dropna(), latitude='Latitude', longitude='Longitude', color="#1338BE")

  # Displaying our definitions of low income
  st.write("### What does low income mean?")
  st.write("""
  This dataset uses area median income (AMI) to determine whether an individual can be considered low income.
  Extremely low is categorized as 0 to 30% of the AMI, while very low is 31 to 50% of the AMI, and low is 51 to 81% of the AMI.
  """)

  # Display evaluation metrics
  with st.expander("### Data Splitting and Model Training"):
    st.write("### Model Evaluation")
    st.write("**Classification Report**")
    st.text(classification_report(y_test, y_pred))
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    st.write(f"**ROC-AUC Score:** {roc_auc:.2f}")

  # Getting evaluation metrics for the "All Features" model
  all_features_results = model_results["All Features"]
  y_test_all = all_features_results["y_test"]
  y_pred_all = all_features_results["y_pred"]
  y_pred_proba_all = all_features_results["y_pred_proba"]
  classification_rep_all = classification_report(y_test_all, y_pred_all)
  roc_auc_all = roc_auc_score(y_test_all, y_pred_proba_all)
  fpr_all, tpr_all, _ = roc_curve(y_test_all, y_pred_proba_all)

  # Plot ROC Curve
  col1, col2 = st.columns(2)
  with col1:
    st.write("### ROC-AUC Curve")
    plt.figure(figsize=(10, 6))
    plt.plot(fpr_all, tpr_all, label=f"ROC Curve (AUC = {roc_auc_all:.2f})")
    plt.plot([0, 1], [0, 1], 'k--', label="Random Guess")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend()
    st.pyplot(plt.gcf())

  # Explaining AUC
  with col1:
    st.write("### What does ROC-AUC mean?")
    st.write("""
    The Receiver Operating Characteristic Area Under the Curve (ROC-AUC) is a metric that measures how good a model is at separation.
    ROC is a measurement of how well a model can separate positive and negative cases. In our case, ROC is measuring the rate at which our model correctly
    separates low-income housing units (positive case) from non-low-income units (negative case). AUC is a single number summarizing how much of the graph
    is "good"--- in other words, how much of the graph correctly predicted true positives and negatives. It ranges from 0 to 1, where 1 is a perfect model.
    Our model has an ROC-AUC score of 0.93, demonstrating accurate separation of low-income and non-low-income housing units.
    """)
    st.write("### Overall...")
    st.write("""
    Our ROC-AUC score indicates that the features we chose for this logistic regression are indicative of whether a housing unit will include low-income
    friendly housing. This information allows us to focus more heavily on advocacy and policy efforts that specifically address inequities in these features,
    such as disparities in low-income housing availability in different boroughs, or across neighborhoods.
    """)

  # Display feature importance (coefficients)
  with col2:
    st.write("### Feature Importance")

    # Extract coefficients
    coefficients = model.coef_[0]  # For binary classification

    # Generate one-hot encoded feature names dynamically
    try:
        categorical_feature_names = encoder.get_feature_names_out([
            'Borough', 'NTA - Neighborhood Tabulation Area',
            'Reporting Construction Type', 'Extended Affordability Only',
            'Prevailing Wage Status'
        ])
    except Exception as e:
        st.error(f"Error in encoding feature names: {e}")
        categorical_feature_names = []

    # Define numerical feature names
    numerical_feature_names = ['Census Tract', 'All Counted Units', 'Total Units']

    # Combine categorical and numerical feature names
    feature_names = list(categorical_feature_names) + numerical_feature_names

    # Check and resolve length mismatch
    if len(feature_names) != len(coefficients):
        #st.error(f"Length mismatch: {len(feature_names)} feature names, {len(coefficients)} coefficients")
        #st.write("Categorical Feature Names:", list(categorical_feature_names))
        #st.write("Numerical Feature Names:", numerical_feature_names)

        # Adjust lengths to match
        if len(feature_names) > len(coefficients):
            feature_names = feature_names[:len(coefficients)]
        elif len(coefficients) > len(feature_names):
            coefficients = coefficients[:len(feature_names)]

    # Create feature importance DataFrame
    feature_importance = pd.DataFrame({
        "Feature": feature_names,
        "Importance": coefficients
    }).sort_values(by="Importance", ascending=False)

    # Display feature importance
    st.write(feature_importance)

  # Explaining feature importance
  with col2:
    st.write("### What does feature importance tell us?")
    st.write("""
      The importance metric is given by the coefficients of each feature in the model. Essentially,
      the coefficients each each feature (e.g., neighborhood, borough, etc.) represent the weight they
      have on the model's prediction. In this model, we see that the type of construction, specifically preservaion, is
      the most predictive feature of a housing unit's likelihood to offer low-income housing. Prevailing wage status and
      number of units are also clearly important features, followed by neighborhood.
    """)
    st.write("### The features we used are:")
    st.markdown("""
      - Borough
      - Census Tract
      - NTA - Neighborhood Tabulation Area
      - Reporting Construction Type
      - Extended Affordability Only
      - Prevailing Wage Status
      - All Counted Units
      - Total Units
      """)

  # Sort by absolute importance and keep the top 20 features
  feature_importance["Absolute Importance"] = feature_importance["Importance"].abs()
  top_features = feature_importance.sort_values(by="Absolute Importance", ascending=False).head(20)

# No construction type
with tab3:
    st.write("""Based on the most important features in our overall model, we trained three alternative models which exclude these features. By doing this,
      we aim to observe the true impacts of these features in the predictive validity of our model, using their absence as a way to see how strongly each feature
      is correlated with successful, accurate prediction. The following model exludes the construction type of the building:""")
    col1, col2 = st.columns(2)
    model_name = "Excluding Construction Type"
    results = model_results[model_name]

    y_test = results["y_test"]
    y_pred_proba = results["y_pred_proba"]
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)

    with col1:
        st.write(f"### ROC-AUC Curve and Score for {model_name}")
        plt.figure(figsize=(10, 6))
        plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.2f})")
        plt.plot([0, 1], [0, 1], 'k--', label="Random Guess")
        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.title(f"ROC Curve for {model_name}")
        plt.legend()
        st.pyplot(plt.gcf())
        st.write(f"**ROC-AUC Score:** {roc_auc:.2f}")

    with col2:
        st.write(f"### What does this mean?")
        st.write("""Construction type, being the most important feature in the model, reduces the ROC-AUC score of the model most significantly (about 7%).
          This shows us that excluding the most highly weighted feature does, in fact, reduce model performance, validating our claim that construction type
          is significant in predicting whether a building will contain low-income housing.""")


# No all counted units
with tab4:
    st.write("""Based on the most important features in our overall model, we trained three alternative models which exclude these features. By doing this,
      we aim to observe the true impacts of these features in the predictive validity of our model, using their absence as a way to see how strongly each feature
      is correlated with successful, accurate prediction. The following model exludes the total number of units in the building:""")
    col1, col2 = st.columns(2)
    model_name = "Excluding All Counted Units"
    results = model_results[model_name]

    y_test = results["y_test"]
    y_pred_proba = results["y_pred_proba"]
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)

    with col1:
        st.write(f"### ROC-AUC Curve for {model_name}")
        plt.figure(figsize=(10, 6))
        plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.2f})")
        plt.plot([0, 1], [0, 1], 'k--', label="Random Guess")
        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.title(f"ROC Curve for {model_name}")
        plt.legend()
        st.pyplot(plt.gcf())
        st.write(f"**ROC-AUC Score:** {roc_auc:.2f}")

    with col2:
        st.write(f"### What does this mean?")
        st.write("""Total number of units in a building is the second most significant feature in the model, and its exclsuionreduces the ROC-AUC score by about 2%.
          This is a significantly smaller change in score than excluding the most highly weighted feature resulted in, which is logical considering its smaller weight.
          Ulimately, though, model performance is still reduced.""")

# No prevailing wage status
with tab5:
    st.write("""Based on the most important features in our overall model, we trained three alternative models which exclude these features. By doing this,
      we aim to observe the true impacts of these features in the predictive validity of our model, using their absence as a way to see how strongly each feature
      is correlated with successful, accurate prediction. The following model exludes the prevailing wage status of the building:""")
    col1, col2 = st.columns(2)
    model_name = "Excluding Prevailing Wage Status"
    results = model_results[model_name]

    y_test = results["y_test"]
    y_pred_proba = results["y_pred_proba"]
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)

    with col1:
        st.write(f"### ROC-AUC Curve for {model_name}")
        plt.figure(figsize=(10, 6))
        plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.2f})")
        plt.plot([0, 1], [0, 1], 'k--', label="Random Guess")
        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.title(f"ROC Curve for {model_name}")
        plt.legend()
        st.pyplot(plt.gcf())
        st.write(f"**ROC-AUC Score:** {roc_auc:.2f}")

    with col2:
        st.write(f"### What does this mean?")
        st.write("""Most surprisingly, excluding prevailing wage status from the model did not reduce model performance at all. This seems counterintuitive, as
          prevailing wage status seems to be a marker of the overall economic standing of residents in a specific building. From this result, it may
          be possible that a better metric for the socioeconomic status of residents is neighborhood or borough, which can be explored in further research.""")

# Feature importance tab
with tab2:
  col3, col4 = st.columns(2)
  # Plot horizontal bar chart
  with col3:
    plt.figure(figsize=(12, 8))  # Increase figure size
    sns.barplot(x="Importance", y="Feature", data=top_features, palette="viridis")
    plt.title("Top 20 Feature Importance", fontsize=16)
    plt.xlabel("Coefficient Value", fontsize=14)
    plt.ylabel("Feature", fontsize=14)
    plt.tight_layout()
    st.pyplot(plt.gcf())

  # Explaining most important features
  with col4:
    st.write("### What are the most important features and what do they mean?")
    st.write("""
      The key features identified in the logistic regression model provide insights into factors influencing whether a housing unit in NYC is likely to include low-income friendly units:
    """)
    st.write("*Construction Type:*")
    st.write("This suggests that the way a building is constructed (e.g., materials, methods, or size) may correlate with the inclusion of low-income units, potentially due to cost considerations or zoning requirements tied to certain construction practices.")
    st.write("*Number of Units:*")
    st.write("Larger or more densely developed buildings may be more likely to include low-income units, possibly because of economies of scale or incentives tied to developments of a certain size.")
    st.write("*Prevailing Wage Status:*")
    st.write("Whether prevailing wages are paid during construction may reflect compliance with government regulations or subsidy programs that incentivize or require low-income housing.")
    st.write("*Neighborhood:*")
    st.write("Geographic location often correlates with economic conditions, zoning laws, or community planning efforts, indicating that some neighborhoods may have policies or characteristics more conducive to low-income housing.")

  # Explaining takeaways
  with col3:
    st.write("### So, what can we gather from this information?")
    st.write("*These features suggest that both structural and policy-driven factors play a significant role in determining the inclusion of low-income friendly housing units, highlighting the interplay between economics, regulation, and urban planning.*")

# Footer
st.markdown("Powered by [Streamlit](https://streamlit.io/)")

